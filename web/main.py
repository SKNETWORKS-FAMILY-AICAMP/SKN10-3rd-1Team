import streamlit as st
from service.constant import HISTORY_INFO, MODEL, ROLE_TYPE, MSG_TYPE
from service.display import print_message, print_history_message, generate_msg
from service.history import init_history, add_history
from service.utils import init_button_session, handle_message, is_txt_file
from service.input import get_prompt
from service.model import make_ai_response
from LLM.llm import load_vector_store, search_similarity, get_answer
from langchain.chat_models import ChatOllama
from dotenv import load_dotenv


st.title("ì‚¼ì„±ì „ì ì·¨ì—… ì»¨ì„¤íŒ… ì±—ë´‡")

# ëª¨ë¸ ì„ íƒ selectbox
col1, col2 = st.columns([1,4])  # 2ê°œì˜ ì—´ë¡œ ë¶„í• 
with col1:
    choice_model = st.selectbox(label="ëª¨ë¸",options=MODEL.__members__)

print_message(ROLE_TYPE.assistant.name,
              "ì•ˆë…•í•˜ì„¸ìš”! ì‚¼ì„±ì „ì ì·¨ì—… ì»¨ì„¤íŒ… ì±—ë´‡ì…ë‹ˆë‹¤. \
              ì›í•˜ì‹œëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”!")

load_dotenv()
init_history()
print_history_message()
init_button_session()
vector_db = load_vector_store()

if st.session_state.profile_clicked == False and st.session_state.posting_clicked == False :
    if st.button("ğŸ“œ ìì†Œì„œ í”¼ë“œë°±"):
        st.session_state.profile_clicked = True
        add_history(ROLE_TYPE.assistant,"ìì†Œì„œ í”¼ë“œë°±ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. \
                    ìì†Œì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì‹œê³ , ì›í•˜ì‹œëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!",
                    MSG_TYPE.system.name)
        st.rerun() # rerun() : ì „ì²´ ì¬ì‹¤í–‰, ë‹¨ sessionì€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ.
        
    if st.button("ğŸ¢ êµ¬ì¸ì˜ë¢° ê²€ìƒ‰"):
        st.session_state.posting_clicked = True
        add_history(ROLE_TYPE.assistant,
                    "êµ¬ì¸ì˜ë¢° ê²€ìƒ‰ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤.",
                    MSG_TYPE.system.name)
        st.rerun() # rerun() : ì „ì²´ ì¬ì‹¤í–‰, ë‹¨ sessionì€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ.

elif st.session_state.profile_clicked == True : 
    prompt = get_prompt(is_file=True)
    if prompt is not None : 
        # ì‚¬ìš©ì ì…ë ¥/ ìì†Œì„œ ì§ˆë¬¸, ë‹µë³€ì„ êµ¬ë¶„ì§“ê¸° ìœ„í•´ msg_typeì„ ì¶”ê°€í•¨.
        # accept_fileì´ ìˆê¸° ë•Œë¬¸ì— chatinputValue ê°ì²´ê°€ ë˜ë‹ˆ .textë¥¼ ë¶™ì—¬ì•¼ë¨.
        handle_message(ROLE_TYPE.user, prompt.text, MSG_TYPE.user.name)
        if not prompt.files : 
            handle_message(ROLE_TYPE.assistant, 
            "ğŸš¨ ì˜¤ë¥˜ : íŒŒì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!!", MSG_TYPE.system.name, is_streaming=True)
        else : 
            file = is_txt_file(prompt.files[0])
            messages = file.read().decode("utf-8")
            context = search_similarity(messages, vector_db)
            llm = ChatOllama(model="gemma3")
            response =  get_answer(llm, context, messages, prompt.text)
            st.write(response)


elif st.session_state.posting_clicked == True :
    prompt = get_prompt(is_file=False)
    if prompt is not None : 
        handle_message(ROLE_TYPE.user, prompt, MSG_TYPE.user.name)



