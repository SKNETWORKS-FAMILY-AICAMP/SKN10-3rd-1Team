import streamlit as st
from service.constant import HISTORY_INFO, MODEL, ROLE_TYPE, MSG_TYPE
from service.display import print_message, print_history_message, generate_msg
from service.history import init_history, add_history
from service.utils import init_button_session, handle_message, is_txt_file
from service.input import get_prompt
from LLM.llm import load_vector_store, search_similarity, get_answer
from langchain.chat_models import ChatOllama
from dotenv import load_dotenv
from service.tavily_tool import tavily_search_korean
from langchain.tools import Tool
import os
from openai import OpenAI

st.title("ì‚¼ì„±ì „ì ì·¨ì—… ì»¨ì„¤íŒ… ì±—ë´‡")

# ëª¨ë¸ ì„ íƒ selectbox
col1, col2 = st.columns([1,4])  # 2ê°œì˜ ì—´ë¡œ ë¶„í• 
with col1:
    choice_model = st.selectbox(label="ëª¨ë¸",options=MODEL.__members__)

print_message(ROLE_TYPE.assistant.name,
              "ì•ˆë…•í•˜ì„¸ìš”! ì‚¼ì„±ì „ì ì·¨ì—… ì»¨ì„¤íŒ… ì±—ë´‡ì…ë‹ˆë‹¤. \
              ì›í•˜ì‹œëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”!")

load_dotenv()
init_history()
print_history_message()
init_button_session()
#vector_db = load_vector_store()  faiss_dbë¥¼ ëª»ì°¾ëŠ”ê²ƒê°™ì•„ì„œ ë‹¤ë¥¸ ê¸°ëŠ¥ ê°œë°œì„ ìœ„í•´ ì¼ë‹¨ ì‘ë™ ì¤‘ì§€ì‹œí‚´.

# api í‚¤ ì„¤ì •
TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


if st.session_state.profile_clicked == False and st.session_state.posting_clicked == False :
    if st.button("ğŸ“œ ìì†Œì„œ í”¼ë“œë°±"):
        st.session_state.profile_clicked = True
        add_history(ROLE_TYPE.assistant,"ğŸ“œ ìì†Œì„œ í”¼ë“œë°±ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. \
                    ìì†Œì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì‹œê³ , ì›í•˜ì‹œëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!",
                    MSG_TYPE.system.name)
        st.rerun() # rerun() : ì „ì²´ ì¬ì‹¤í–‰, ë‹¨ sessionì€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ.
        
    if st.button("ğŸ¢ êµ¬ì¸ì˜ë¢° ê²€ìƒ‰"):
        st.session_state.posting_clicked = True
        add_history(ROLE_TYPE.assistant,
                    "ğŸ¢ êµ¬ì¸ì˜ë¢° ê²€ìƒ‰ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ì‚¼ì„±ì „ì ì±„ìš©, ë‰´ìŠ¤, íŠ¸ë Œë“œ ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©í•´ì£¼ì„¸ìš”~",
                    MSG_TYPE.system.name)
        st.rerun() # rerun() : ì „ì²´ ì¬ì‹¤í–‰, ë‹¨ sessionì€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ.

elif st.session_state.profile_clicked == True : 
    prompt = get_prompt(is_file=True)
    if prompt is not None : 
        # ì‚¬ìš©ì ì…ë ¥/ ìì†Œì„œ ì§ˆë¬¸, ë‹µë³€ì„ êµ¬ë¶„ì§“ê¸° ìœ„í•´ msg_typeì„ ì¶”ê°€í•¨.
        # accept_fileì´ ìˆê¸° ë•Œë¬¸ì— chatinputValue ê°ì²´ê°€ ë˜ë‹ˆ .textë¥¼ ë¶™ì—¬ì•¼ë¨.
        handle_message(ROLE_TYPE.user, prompt.text, MSG_TYPE.user.name)
        if not prompt.files : 
            handle_message(ROLE_TYPE.assistant, 
            "ğŸš¨ ì˜¤ë¥˜ : íŒŒì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!!", MSG_TYPE.system.name, is_streaming=True)
        else : 
            file = is_txt_file(prompt.files[0])
            messages = file.read().decode("utf-8")
            context = search_similarity(messages, vector_db)
            llm = ChatOllama(model="gemma3")
            response =  get_answer(llm, context, messages, prompt.text)
            st.write(response)


elif st.session_state.posting_clicked == True :
    prompt = get_prompt(is_file=False)
    if prompt is not None : 
        handle_message(ROLE_TYPE.user, prompt, MSG_TYPE.user.name)

        # âœ… LangChain Tool ê°ì²´ ìƒì„±
        tavily_tool = Tool(
            name="TavilySearchKorean",
            func=tavily_search_korean,
            description=(
                "ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œê¸€ë¡œ ìš”ì•½í•´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. "
                "ì‚¼ì„±ì „ì ì±„ìš©, ë‰´ìŠ¤, íŠ¸ë Œë“œ ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”."
            )
        )
        result = tavily_search_korean(prompt, tavily_key=TAVILY_API_KEY, openai_key=OPENAI_API_KEY)
        handle_message(ROLE_TYPE.assistant, 
        "ğŸ” ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ (í•œêµ­ì–´): " + result, MSG_TYPE.ai.name, is_streaming=True)

